{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca45f2c",
   "metadata": {},
   "source": [
    "## Final_Project.ipynb Contents\n",
    "\n",
    "This notebook covers the complete workflow for brain tumor segmentation using deep learning (U-Net) on the BraTS dataset:\n",
    "\n",
    "- **Data Loading & Preprocessing**\n",
    "  - Loads multi-modal MRI data (FLAIR, T1, T1ce, T2) and segmentation masks for each subject.\n",
    "  - Preprocesses each slice: normalization, resizing, and filtering out empty masks.\n",
    "\n",
    "- **Model Architecture**\n",
    "  - Defines a U-Net model with batch normalization and dropout for robust segmentation.\n",
    "\n",
    "- **Training**\n",
    "  - Splits data into training and validation sets.\n",
    "  - Trains the U-Net model and saves the trained weights.\n",
    "\n",
    "- **Evaluation**\n",
    "  - Predicts on the validation set.\n",
    "  - Calculates Dice and IoU metrics.\n",
    "  - Visualizes random samples of input, ground truth, and predictions.\n",
    "\n",
    "- **Testing**\n",
    "  - For testing the trained model on new data, use the provided `test_model.ipynb`.\n",
    "\n",
    "> **Note:**  \n",
    "> The MRI subject folders should contain the following files (BraTS format):  \n",
    "> - `<subject_id>_flair.nii.gz`  \n",
    "> - `<subject_id>_t1.nii.gz`  \n",
    "> - `<subject_id>_t1ce.nii.gz`  \n",
    "> - `<subject_id>_t2.nii.gz`  \n",
    "> - `<subject_id>_seg.nii.gz`  \n",
    "> All files must be named with the same `<subject_id>` prefix as the folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83370e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modalities(subject_path, modalities=['flair', 't1', 't1ce', 't2']):\n",
    "    vols = []\n",
    "    for mod in modalities:\n",
    "        nii = nib.load(os.path.join(subject_path, f\"{os.path.basename(subject_path)}_{mod}.nii.gz\"))\n",
    "        vols.append(nii.get_fdata())\n",
    "    return np.stack(vols, axis=-1)\n",
    "\n",
    "def load_mask(subject_path):\n",
    "    nii = nib.load(os.path.join(subject_path, f\"{os.path.basename(subject_path)}_seg.nii.gz\"))\n",
    "    return nii.get_fdata()\n",
    "\n",
    "def preprocess_volume(volume, mask, target_size=(128, 128)):\n",
    "    X, y = [], []\n",
    "    for i in range(volume.shape[2]):\n",
    "        img_slice = volume[:, :, i, :]\n",
    "        mask_slice = mask[:, :, i]\n",
    "\n",
    "        if np.max(mask_slice) == 0:\n",
    "            continue\n",
    "\n",
    "        img_slice = (img_slice - np.min(img_slice, axis=(0, 1))) / (np.ptp(img_slice, axis=(0, 1)) + 1e-8)\n",
    "        img_slice = tf.image.resize(img_slice, target_size).numpy()\n",
    "\n",
    "        mask_slice = tf.image.resize(mask_slice[..., None], target_size, method='nearest').numpy().squeeze()\n",
    "        mask_slice = np.rint(mask_slice).astype(np.uint8)     # keep integer labels after resize\n",
    "        mask_slice[mask_slice == 4] = 3                       # remap BraTS label 4 -> class 3\n",
    "        mask_slice = np.clip(mask_slice, 0, 3).astype(np.uint8)\n",
    "\n",
    "        X.append(img_slice)\n",
    "        y.append(mask_slice)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59559252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jyotirya-agrawal/.cache/kagglehub/datasets/dschettler8845/brats-2021-task1/versions/1/BraTS2021_Training_Data\"\n",
    "subjects = [os.path.join(data_dir, d) for d in os.listdir(data_dir) if d.startswith(\"BraTS2021\")]\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for subj in subjects[:200]: \n",
    "    vol = load_modalities(subj)\n",
    "    mask = load_mask(subj)\n",
    "    X, y = preprocess_volume(vol, mask)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "y_all = np.rint(y_all).astype(np.uint8)\n",
    "y_all[y_all == 4] = 3\n",
    "y_all = np.clip(y_all, 0, 3).astype(np.uint8)\n",
    "\n",
    "print(\"X_all shape:\", X_all.shape, \"y_all shape:\", y_all.shape)\n",
    "print(\"Unique labels (after remap):\", np.unique(y_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, use_bn=True):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', kernel_initializer='he_normal', use_bias=not use_bn)(x)\n",
    "    if use_bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding='same', kernel_initializer='he_normal', use_bias=not use_bn)(x)\n",
    "    if use_bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape=(128, 128, 4), base_filters=16, num_classes=4):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    c1 = conv_block(inputs, base_filters);     p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = conv_block(p1, base_filters * 2);     p2 = layers.MaxPooling2D()(c2)\n",
    "    c3 = conv_block(p2, base_filters * 4);     p3 = layers.MaxPooling2D()(c3)\n",
    "    c4 = conv_block(p3, base_filters * 8);     p4 = layers.MaxPooling2D()(c4)\n",
    "\n",
    "    bn = conv_block(p4, base_filters * 16)\n",
    "    bn = layers.Dropout(0.3)(bn)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(base_filters * 8, 2, strides=2, padding='same')(bn)\n",
    "    u1 = layers.Concatenate()([u1, c4]); c5 = conv_block(u1, base_filters * 8)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding='same')(c5)\n",
    "    u2 = layers.Concatenate()([u2, c3]); c6 = conv_block(u2, base_filters * 4)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding='same')(c6)\n",
    "    u3 = layers.Concatenate()([u3, c2]); c7 = conv_block(u3, base_filters * 2)\n",
    "\n",
    "    u4 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding='same')(c7)\n",
    "    u4 = layers.Concatenate()([u4, c1]); c8 = conv_block(u4, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, activation='softmax')(c8)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc11ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return 1 - (2. * intersection + smooth) / (\n",
    "        K.sum(y_true) + K.sum(y_pred) + smooth\n",
    "    )\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return (\n",
    "        K.binary_crossentropy(y_true, y_pred)\n",
    "        + dice_loss(y_true, y_pred)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6caa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4\n",
    "\n",
    "unet = build_unet(num_classes=NUM_CLASSES)\n",
    "unet.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "history = unet.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save(\"unet_brats_segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786df6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_iou_per_class(y_true, y_pred, num_classes=4, smooth=1e-6):\n",
    "    dices, ious = [], []\n",
    "    for c in range(num_classes):\n",
    "        yt = (y_true == c).astype(np.float32)\n",
    "        yp = (y_pred == c).astype(np.float32)\n",
    "\n",
    "        inter = np.sum(yt * yp)\n",
    "        dice = (2.0 * inter + smooth) / (np.sum(yt) + np.sum(yp) + smooth)\n",
    "\n",
    "        union = np.sum(yt) + np.sum(yp) - inter\n",
    "        iou = (inter + smooth) / (union + smooth)\n",
    "\n",
    "        dices.append(dice)\n",
    "        ious.append(iou)\n",
    "    return dices, ious\n",
    "\n",
    "y_prob = unet.predict(X_val)\n",
    "y_pred = np.argmax(y_prob, axis=-1).astype(np.uint8)\n",
    "y_true = y_val.astype(np.uint8)\n",
    "\n",
    "acc = np.mean(y_pred == y_true)\n",
    "dices, ious = dice_iou_per_class(y_true, y_pred, num_classes=NUM_CLASSES)\n",
    "\n",
    "print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "for c in range(NUM_CLASSES):\n",
    "    print(f\"Class {c} -> Dice: {dices[c]:.4f}, IoU: {ious[c]:.4f}\")\n",
    "print(f\"Mean Dice (tumor classes 1-3): {np.mean(dices[1:]):.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(X, y_true_lbl, y_pred_lbl, idx):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(X[idx][..., 0], cmap='gray')\n",
    "    plt.title('FLAIR (example)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_true_lbl[idx], cmap='tab10', vmin=0, vmax=NUM_CLASSES - 1)\n",
    "    plt.title('Ground Truth (classes)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(y_pred_lbl[idx], cmap='tab10', vmin=0, vmax=NUM_CLASSES - 1)\n",
    "    plt.title('Prediction (classes)')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for _ in range(10):\n",
    "    index = np.random.randint(0, X_val.shape[0])\n",
    "    plot_sample(X_val, y_true, y_pred, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Global Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
