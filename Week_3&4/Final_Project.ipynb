{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca45f2c",
   "metadata": {},
   "source": [
    "## Final_Project.ipynb Contents\n",
    "\n",
    "This notebook covers the complete workflow for brain tumor segmentation using deep learning (U-Net) on the BraTS dataset:\n",
    "\n",
    "- **Data Loading & Preprocessing**\n",
    "  - Loads multi-modal MRI data (FLAIR, T1, T1ce, T2) and segmentation masks for each subject.\n",
    "  - Preprocesses each slice: normalization, resizing, and filtering out empty masks.\n",
    "\n",
    "- **Model Architecture**\n",
    "  - Defines a U-Net model with batch normalization and dropout for robust segmentation.\n",
    "\n",
    "- **Loss Functions**\n",
    "  - Implements Dice loss and a combined BCE + Dice loss for training.\n",
    "\n",
    "- **Training**\n",
    "  - Splits data into training and validation sets.\n",
    "  - Trains the U-Net model and saves the trained weights.\n",
    "\n",
    "- **Evaluation**\n",
    "  - Predicts on the validation set.\n",
    "  - Calculates Dice and IoU metrics.\n",
    "  - Visualizes random samples of input, ground truth, and predictions.\n",
    "\n",
    "- **Testing**\n",
    "  - For testing the trained model on new data, use the provided `test_model.ipynb`.\n",
    "\n",
    "> **Note:**  \n",
    "> The MRI subject folders should contain the following files (BraTS format):  \n",
    "> - `<subject_id>_flair.nii.gz`  \n",
    "> - `<subject_id>_t1.nii.gz`  \n",
    "> - `<subject_id>_t1ce.nii.gz`  \n",
    "> - `<subject_id>_t2.nii.gz`  \n",
    "> - `<subject_id>_seg.nii.gz`  \n",
    "> All files must be named with the same `<subject_id>` prefix as the folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83370e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modalities(subject_path, modalities=['flair', 't1', 't1ce', 't2']):\n",
    "    vols = []\n",
    "    for mod in modalities:\n",
    "        nii = nib.load(os.path.join(subject_path, f\"{os.path.basename(subject_path)}_{mod}.nii.gz\"))\n",
    "        vols.append(nii.get_fdata())\n",
    "    return np.stack(vols, axis=-1)\n",
    "\n",
    "def load_mask(subject_path):\n",
    "    nii = nib.load(os.path.join(subject_path, f\"{os.path.basename(subject_path)}_seg.nii.gz\"))\n",
    "    return nii.get_fdata()\n",
    "\n",
    "def preprocess_volume(volume, mask, target_size=(128, 128)):\n",
    "    X, y = [], []\n",
    "    for i in range(volume.shape[2]):\n",
    "        img_slice = volume[:, :, i, :] \n",
    "        mask_slice = mask[:, :, i]    \n",
    "        if np.max(mask_slice) == 0:\n",
    "            continue\n",
    "        img_slice = (img_slice - np.min(img_slice, axis=(0,1))) / (np.ptp(img_slice, axis=(0,1)) + 1e-8)\n",
    "        img_slice = tf.image.resize(img_slice, target_size).numpy()\n",
    "        mask_slice = tf.image.resize(mask_slice[..., None], target_size, method='nearest').numpy().squeeze()\n",
    "        X.append(img_slice)\n",
    "        y.append(mask_slice)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59559252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jyotirya-agrawal/.cache/kagglehub/datasets/dschettler8845/brats-2021-task1/versions/1/BraTS2021_Training_Data\"\n",
    "subjects = [os.path.join(data_dir, d) for d in os.listdir(data_dir) if d.startswith(\"BraTS2021\")]\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for subj in subjects:  # Use a subset for demo/training speed\n",
    "    vol = load_modalities(subj)\n",
    "    mask = load_mask(subj)\n",
    "    X, y = preprocess_volume(vol, mask)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "y_all = (y_all > 0).astype(np.float32)  # Binary mask\n",
    "print(\"X_all shape:\", X_all.shape, \"y_all shape:\", y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, use_bn=True):\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal',\n",
    "        use_bias=not use_bn\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal',\n",
    "        use_bias=not use_bn\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet(input_shape=(128, 128, 4), base_filters=16):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ---------- Encoder ----------\n",
    "    c1 = conv_block(inputs, base_filters)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = conv_block(p1, base_filters * 2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "\n",
    "    c3 = conv_block(p2, base_filters * 4)\n",
    "    p3 = layers.MaxPooling2D()(c3)\n",
    "\n",
    "    c4 = conv_block(p3, base_filters * 8)\n",
    "    p4 = layers.MaxPooling2D()(c4)\n",
    "\n",
    "    # ---------- Bottleneck ----------\n",
    "    bn = conv_block(p4, base_filters * 16)\n",
    "    bn = layers.Dropout(0.3)(bn)\n",
    "\n",
    "    # ---------- Decoder ----------\n",
    "    u1 = layers.Conv2DTranspose(base_filters * 8, 2, strides=2, padding='same')(bn)\n",
    "    u1 = layers.Concatenate()([u1, c4])\n",
    "    c5 = conv_block(u1, base_filters * 8)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding='same')(c5)\n",
    "    u2 = layers.Concatenate()([u2, c3])\n",
    "    c6 = conv_block(u2, base_filters * 4)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding='same')(c6)\n",
    "    u3 = layers.Concatenate()([u3, c2])\n",
    "    c7 = conv_block(u3, base_filters * 2)\n",
    "\n",
    "    u4 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding='same')(c7)\n",
    "    u4 = layers.Concatenate()([u4, c1])\n",
    "    c8 = conv_block(u4, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(1, kernel_size=1, activation='sigmoid')(c8)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc11ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return 1 - (2. * intersection + smooth) / (\n",
    "        K.sum(y_true) + K.sum(y_pred) + smooth\n",
    "    )\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return (\n",
    "        K.binary_crossentropy(y_true, y_pred)\n",
    "        + dice_loss(y_true, y_pred)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6caa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = build_unet()\n",
    "unet.compile(\n",
    "    optimizer='adam',\n",
    "    loss=bce_dice_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "unet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "history = unet.fit(\n",
    "    X_train, y_train[..., None],\n",
    "    validation_data=(X_val, y_val[..., None]),\n",
    "    epochs=10,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save(\"unet_brats_segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786df6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_score(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = unet.predict(X_val)\n",
    "y_pred_bin = (y_pred > 0.5).astype(np.float32)\n",
    "\n",
    "dice = dice_coef(y_val, y_pred_bin)\n",
    "iou = iou_score(y_val, y_pred_bin)\n",
    "print(f\"Dice Score: {dice:.4f}, IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(X, y_true, y_pred, idx):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(X[idx][...,0], cmap='gray')\n",
    "    plt.title('FLAIR (example)')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(y_true[idx], cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y_pred[idx].squeeze(), cmap='gray')\n",
    "    plt.title('Prediction')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "for i in range(10):\n",
    "    index = np.random.randint(0, X_val.shape[0])\n",
    "    plot_sample(X_val, y_val, y_pred_bin,index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Global Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
